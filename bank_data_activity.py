# -*- coding: utf-8 -*-
"""Bank_data_activity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uNB73d5QsFTn_p_Ve9LujQxY75vaHJNV
"""

import os
import pandas as pd

bank=pd.read_csv('Bank_Personal_Loan_Modelling.csv')

print(bank.shape)
print(type(bank))

print(bank.columns)
print(bank.dtypes)

bank.head(3)

"""# Check the missing values """

bank.isnull().sum()

"""# Check the Frequency of Target Varaible(value_counts())"""

bank["Personal Loan"].value_counts()

bank.set_index(bank["ID"],inplace=True)

bank.head()

"""# Drop Id column """

bank=bank.drop(["ID","ZIP Code"],axis=1)

bank.head(6)

bank.describe(include='all')

catcols = ['Education','CD Account','Online',
           'CreditCard','Securities Account']
bank[catcols]=bank[catcols].astype('category')

#bank[bank.select_dtypes(['object']).columns] = bank.select_dtypes(['object']).apply(lambda x: x.astype('category'))

bank.dtypes

bank["Personal Loan"].value_counts(normalize=True)

from sklearn.model_selection import train_test_split

bank['Personal Loan']=bank['Personal Loan'].astype('category')
# Divide in to train and test
y=bank["Personal Loan"]
X=bank.drop('Personal Loan', axis=1)
#from sklearn.model_selection import train_test_split  
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, )

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""### Standardize the data (numerical attributes only)( import StandardScaler)"""

from sklearn.preprocessing import StandardScaler
num_atr=X_train.select_dtypes(['int64','float64']).columns
num_atr

scaler = StandardScaler()
scaler.fit(X_train[num_atr])

X_train[num_atr]=scaler.transform(X_train[num_atr])
X_test[num_atr]=scaler.transform(X_test[num_atr])

print(X_train.shape)
print(X_test.shape)

from sklearn.linear_model import LogisticRegression

model=LogisticRegression()
model.fit(X_train,y_train)

X_train_pred=model.predict(X_train)
X_test_pred=model.predict(X_test)

from sklearn.metrics import accuracy_score,precision_score

accuracy_score(y_train,X_train_pred)

precision_score(y_train,X_train_pred)

y_pred=model.predict(X_test)

import pickle
print('saving model as pkl file.......')
pickle.dump(model, open('model.pkl','wb'))

model = pickle.load(open('model.pkl','rb'))

